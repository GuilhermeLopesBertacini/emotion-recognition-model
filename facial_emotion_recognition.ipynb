{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMlkfRRmhbvKvEFLKQURbHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilhermeLopesBertacini/emotion-recognition-model/blob/main/facial_emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Modules"
      ],
      "metadata": {
        "id": "RiCSCSbi-Lnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KyaILZMMllO"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "NKj51jsQ-uVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "SIpqSEYj-s78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/kaggle/input/fer2013/train/'\n",
        "TEST_DIR = '/kaggle/input/fer2013/test/'"
      ],
      "metadata": {
        "id": "S7jc0Q2_-s5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir: str) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Load image paths and their corresponding labels from a directory structure.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): The absolute path to the data directory\n",
        "                        (e.g., train_dir, test_dir). Each subdirectory should be a label.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[str]]: A tuple containing:\n",
        "            - A list of full image file paths.\n",
        "            - A list of corresponding labels.\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for label in sorted(os.listdir(data_dir)):\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "\n",
        "        for image_name in sorted(os.listdir(label_dir)):\n",
        "            image_path = os.path.join(label_dir, image_name)\n",
        "\n",
        "            image_paths.append(image_path)\n",
        "            labels.append(label)\n",
        "        print(f\"{label} completed\")\n",
        "    return image_paths, labels"
      ],
      "metadata": {
        "id": "z977mQzK-s24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert into df\n",
        "train = pd.DataFrame()\n",
        "train['image'], train['label'] = load_data(TRAIN_DIR)\n",
        "# shuffle the dataset\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "_R_pXSzy-s0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame()\n",
        "test['image'], test['label'] = load_data(TEST_DIR)\n",
        "test.head()"
      ],
      "metadata": {
        "id": "yiOAVFIp-sxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis\n"
      ],
      "metadata": {
        "id": "_EA8KimRKU4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=train['label'])\n",
        "plt.title(\"Label Distribution\")"
      ],
      "metadata": {
        "id": "yB8cjEru-svW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(train['image'][0])\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "metadata": {
        "id": "DKAbYCSk-ssw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display grid of images\n",
        "plt.figure(figsize=(10, 10))\n",
        "files = train.iloc[0:25]\n",
        "\n",
        "for index, file, label in files.itertuples():\n",
        "  plt.subplot(5, 5, index+1)\n",
        "  img = load_img(file)\n",
        "  img = np.array(img)\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(label)\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "Qjofqz8T-sqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "3dvBouGGOAaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images):\n",
        "  features = []\n",
        "  for image in tqdm(images):\n",
        "    img = load_img(image, color_mode='grayscale', target_size=(48, 48))\n",
        "    img = np.array(img)\n",
        "    features.append(img)\n",
        "  features = np.array(features)\n",
        "  return features # shape (N, 48, 48, 1)"
      ],
      "metadata": {
        "id": "dpdlt03Q-sgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = extract_features(train['image'])"
      ],
      "metadata": {
        "id": "3diUXPz2REQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = extract_features(test['image'])"
      ],
      "metadata": {
        "id": "DmqA-qlhRocV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features[0][0])"
      ],
      "metadata": {
        "id": "8rdgrlxhSFB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalize images\n",
        "x_train = train_features/255.0\n",
        "x_test = test_features/255.0"
      ],
      "metadata": {
        "id": "_4Dq2x34RoaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert labels to integers\n",
        "le = LabelEncoder()\n",
        "le.fit(train['label'])\n",
        "\n",
        "y_train = le.transform(train['label'])\n",
        "y_test = le.transform(test['label'])"
      ],
      "metadata": {
        "id": "zhLYtCnxRoXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "num_classes = len(os.listdir(TRAIN_DIR))"
      ],
      "metadata": {
        "id": "TqaEGKNoRoU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "1Wk8GkH8Lqdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]\n",
        "# The index corresponds to the classes"
      ],
      "metadata": {
        "id": "kE4BAzGLRoSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model's architecture.\n",
        "\n",
        "### Convolutional Layers (Conv2D)\n",
        "These layers act as **feature detectors**, using learnable filters to find patterns like edges and textures. Deeper layers combine these to recognize more complex objects.\n",
        "\n",
        "---\n",
        "\n",
        "### Activation Function (ReLU)\n",
        "ReLU ($f(x) = \\max(0, x)$) introduces crucial **non-linearity**. It's computationally fast and helps prevent the **vanishing gradient problem**, enabling effective training of deep networks.\n",
        "\n",
        "---\n",
        "\n",
        "### Pooling Layers (MaxPooling & GlobalAveragePooling)\n",
        "**Max Pooling** downsamples feature maps, making the learned features more robust to small shifts and reducing computation. **Global Average Pooling** converts the final feature maps into a single vector for classification, significantly reducing parameters and helping to prevent overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### Dropout\n",
        "This is a regularization technique to **prevent overfitting**. It randomly ignores a fraction of neurons during training, forcing the network to learn more robust features. The dropout rate is increased in later layers where overfitting is a greater risk.\n",
        "\n",
        "---\n",
        "\n",
        "### Batch Normalization\n",
        "Applied after convolutions, this technique normalizes the activations. This leads to **faster, more stable training** and makes the network less sensitive to the initial weight configuration.\n",
        "\n",
        "---\n",
        "\n",
        "### Dense Layers\n",
        "These fully connected layers act as the **classifier**. They take the high-level features extracted by the convolutional blocks and make a final prediction. The last layer uses a **softmax** activation to output a probability for each class."
      ],
      "metadata": {
        "id": "Fv9E6mOEMriW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # Block 1\n",
        "    Conv2D(64, (3, 3), input_shape=(48, 48, 1), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Block 2\n",
        "    Conv2D(128, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Block 3\n",
        "    Conv2D(256, (3, 3), strides=(2, 2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 4\n",
        "    Conv2D(512, (3, 3), strides=(2, 2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "vQutlulfRoP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "spVdDwnlUw5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "lH0IwOtYRoNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "u99MF_frw_xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Results"
      ],
      "metadata": {
        "id": "S4GfGYDYMbXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzVM4NDUMTMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "WeJflXnmOVko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "model.save(\"emotion_recognition_model.h5\")\n",
        "files.download(\"emotion_recognition_model.h5\")"
      ],
      "metadata": {
        "id": "62fkfE3dOXya"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}